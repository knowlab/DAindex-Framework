{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [`aif360`](https://aif360.readthedocs.io/en/latest/Getting%20Started.html) package to load the UCI adult dataset, fit a simple model and then analyse the fairness of the model using the DA-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code downloads the required files from the UCI website if they are not already present in ai360's data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import aif360\n",
    "\n",
    "aif360_location = os.path.dirname(aif360.__file__)\n",
    "meps_data_dir = os.path.join(aif360_location, \"data\", \"raw\", \"meps\")\n",
    "h181_file_path = os.path.join(meps_data_dir, \"h181.csv\")\n",
    "\n",
    "if not os.path.isfile(h181_file_path):\n",
    "    r_script_path = os.path.join(meps_data_dir, \"generate_data.R\")\n",
    "    process = subprocess.Popen([\"Rscript\", r_script_path], stdin=subprocess.PIPE)\n",
    "    process.communicate(input=b\"y\\n\")\n",
    "\n",
    "    # Move the generated CSV files to meps_data_dir\n",
    "    generated_files = [\"h181.csv\", \"h192.csv\"]\n",
    "    for file_name in generated_files:\n",
    "        src_path = os.path.join(os.getcwd(), file_name)\n",
    "        dest_path = os.path.join(meps_data_dir, file_name)\n",
    "        if os.path.isfile(src_path):\n",
    "            shutil.move(src_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_w_multimorb(df):\n",
    "    \"\"\"\n",
    "    1.Create a new column, RACE that is 'White' if RACEV2X = 1 and HISPANX = 2 i.e. non Hispanic White\n",
    "      and 'non-White' otherwise\n",
    "    2. Restrict to Panel 19\n",
    "    3. RENAME all columns that are PANEL/ROUND SPECIFIC\n",
    "    4. Drop rows based on certain values of individual features that correspond to missing/unknown - generally < -1\n",
    "    5. Compute UTILIZATION, binarize it to 0 (< 10) and 1 (>= 10)\n",
    "    \"\"\"\n",
    "\n",
    "    def race(row):\n",
    "        if (row[\"HISPANX\"] == 2) and (\n",
    "            row[\"RACEV2X\"] == 1\n",
    "        ):  # non-Hispanic Whites are marked as WHITE; all others as NON-WHITE\n",
    "            return \"White\"\n",
    "        return \"Non-White\"\n",
    "\n",
    "    df[\"RACEV2X\"] = df.apply(lambda row: race(row), axis=1)\n",
    "    df = df.rename(columns={\"RACEV2X\": \"RACE\"})\n",
    "\n",
    "    df = df[df[\"PANEL\"] == 19]\n",
    "\n",
    "    # RENAME COLUMNS\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"FTSTU53X\": \"FTSTU\",\n",
    "            \"ACTDTY53\": \"ACTDTY\",\n",
    "            \"HONRDC53\": \"HONRDC\",\n",
    "            \"RTHLTH53\": \"RTHLTH\",\n",
    "            \"MNHLTH53\": \"MNHLTH\",\n",
    "            \"CHBRON53\": \"CHBRON\",\n",
    "            \"JTPAIN53\": \"JTPAIN\",\n",
    "            \"PREGNT53\": \"PREGNT\",\n",
    "            \"WLKLIM53\": \"WLKLIM\",\n",
    "            \"ACTLIM53\": \"ACTLIM\",\n",
    "            \"SOCLIM53\": \"SOCLIM\",\n",
    "            \"COGLIM53\": \"COGLIM\",\n",
    "            \"EMPST53\": \"EMPST\",\n",
    "            \"REGION53\": \"REGION\",\n",
    "            \"MARRY53X\": \"MARRY\",\n",
    "            \"AGE53X\": \"AGE\",\n",
    "            \"POVCAT15\": \"POVCAT\",\n",
    "            \"INSCOV15\": \"INSCOV\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df = df[df[\"REGION\"] >= 0]  # remove values -1\n",
    "    df = df[df[\"AGE\"] >= 0]  # remove values -1\n",
    "\n",
    "    df = df[df[\"MARRY\"] >= 0]  # remove values -1, -7, -8, -9\n",
    "\n",
    "    df = df[df[\"ASTHDX\"] >= 0]  # remove values -1, -7, -8, -9\n",
    "\n",
    "    df = df[\n",
    "        (\n",
    "            df[\n",
    "                [\n",
    "                    \"FTSTU\",\n",
    "                    \"ACTDTY\",\n",
    "                    \"HONRDC\",\n",
    "                    \"RTHLTH\",\n",
    "                    \"MNHLTH\",\n",
    "                    \"HIBPDX\",\n",
    "                    \"CHDDX\",\n",
    "                    \"ANGIDX\",\n",
    "                    \"EDUCYR\",\n",
    "                    \"HIDEG\",\n",
    "                    \"MIDX\",\n",
    "                    \"OHRTDX\",\n",
    "                    \"STRKDX\",\n",
    "                    \"EMPHDX\",\n",
    "                    \"CHBRON\",\n",
    "                    \"CHOLDX\",\n",
    "                    \"CANCERDX\",\n",
    "                    \"DIABDX\",\n",
    "                    \"JTPAIN\",\n",
    "                    \"ARTHDX\",\n",
    "                    \"ARTHTYPE\",\n",
    "                    \"ASTHDX\",\n",
    "                    \"ADHDADDX\",\n",
    "                    \"PREGNT\",\n",
    "                    \"WLKLIM\",\n",
    "                    \"ACTLIM\",\n",
    "                    \"SOCLIM\",\n",
    "                    \"COGLIM\",\n",
    "                    \"DFHEAR42\",\n",
    "                    \"DFSEE42\",\n",
    "                    \"ADSMOK42\",\n",
    "                    \"PHQ242\",\n",
    "                    \"EMPST\",\n",
    "                    \"POVCAT\",\n",
    "                    \"INSCOV\",\n",
    "                ]\n",
    "            ]\n",
    "            >= -1\n",
    "        ).all(1)\n",
    "    ]  # for all other categorical features, remove values < -1\n",
    "\n",
    "    def utilization(row):\n",
    "        return row[\"OBTOTV15\"] + row[\"OPTOTV15\"] + row[\"ERTOT15\"] + row[\"IPNGTD15\"] + row[\"HHTOTD15\"]\n",
    "\n",
    "    df[\"TOTEXP15\"] = df.apply(lambda row: utilization(row), axis=1)\n",
    "    lessE = df[\"TOTEXP15\"] < 10.0\n",
    "    df.loc[lessE, \"TOTEXP15\"] = 0.0\n",
    "    moreE = df[\"TOTEXP15\"] >= 10.0\n",
    "    df.loc[moreE, \"TOTEXP15\"] = 1.0\n",
    "    df[\"MULTIMORBIDITY\"] = (\n",
    "        df.filter(regex=\"DX$|CHBRON$|JTPAIN$\").drop(columns=[\"ADHDADDX\"]).apply(lambda x: (x == 1).sum(), axis=1)\n",
    "    )\n",
    "\n",
    "    df = df.rename(columns={\"TOTEXP15\": \"UTILIZATION\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test = MEPSDataset19(\n",
    "    custom_preprocessing=preprocessing_w_multimorb,\n",
    "    features_to_keep=[\n",
    "        \"REGION\",\n",
    "        \"AGE\",\n",
    "        \"SEX\",\n",
    "        \"RACE\",\n",
    "        \"MARRY\",\n",
    "        \"FTSTU\",\n",
    "        \"ACTDTY\",\n",
    "        \"HONRDC\",\n",
    "        \"RTHLTH\",\n",
    "        \"MNHLTH\",\n",
    "        \"HIBPDX\",\n",
    "        \"CHDDX\",\n",
    "        \"ANGIDX\",\n",
    "        \"MIDX\",\n",
    "        \"OHRTDX\",\n",
    "        \"STRKDX\",\n",
    "        \"EMPHDX\",\n",
    "        \"CHBRON\",\n",
    "        \"CHOLDX\",\n",
    "        \"CANCERDX\",\n",
    "        \"DIABDX\",\n",
    "        \"JTPAIN\",\n",
    "        \"ARTHDX\",\n",
    "        \"ARTHTYPE\",\n",
    "        \"ASTHDX\",\n",
    "        \"ADHDADDX\",\n",
    "        \"PREGNT\",\n",
    "        \"WLKLIM\",\n",
    "        \"ACTLIM\",\n",
    "        \"SOCLIM\",\n",
    "        \"COGLIM\",\n",
    "        \"DFHEAR42\",\n",
    "        \"DFSEE42\",\n",
    "        \"ADSMOK42\",\n",
    "        \"PCS42\",\n",
    "        \"MCS42\",\n",
    "        \"K6SUM42\",\n",
    "        \"PHQ242\",\n",
    "        \"EMPST\",\n",
    "        \"POVCAT\",\n",
    "        \"INSCOV\",\n",
    "        \"UTILIZATION\",\n",
    "        \"PERWT15F\",\n",
    "        \"MULTIMORBIDITY\",\n",
    "    ],\n",
    ").split([0.5, 0.8], shuffle=True)\n",
    "\n",
    "sens_ind = 0\n",
    "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
    "\n",
    "unprivileged_groups = [{sens_attr: v} for v in dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]]\n",
    "privileged_groups = [{sens_attr: v} for v in dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(train=None, val=None, test=None):\n",
    "    if train is not None:\n",
    "        print(train.features.shape)\n",
    "    if val is not None:\n",
    "        print(val.features.shape)\n",
    "    print(test.features.shape)\n",
    "    print(test.favorable_label, test.unfavorable_label)\n",
    "    print(test.protected_attribute_names)\n",
    "    print(test.privileged_protected_attributes, test.unprivileged_protected_attributes)\n",
    "    print(test.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_panel19_train = BinaryLabelDatasetMetric(\n",
    "    dataset_orig_panel19_train, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups\n",
    ")\n",
    "explainer_orig_panel19_train = MetricTextExplainer(metric_orig_panel19_train)\n",
    "\n",
    "print(explainer_orig_panel19_train.disparate_impact())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_orig_panel19_train\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression(solver=\"liblinear\", random_state=1))\n",
    "fit_params = {\"logisticregression__sample_weight\": dataset.instance_weights}\n",
    "\n",
    "lr_orig_panel19 = model.fit(dataset.features, dataset.labels.ravel(), **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def test(dataset, model, thresh_arr):\n",
    "    try:\n",
    "        # sklearn classifier\n",
    "        y_val_pred_prob = model.predict_proba(dataset.features)\n",
    "        pos_ind = np.where(model.classes_ == dataset.favorable_label)[0][0]\n",
    "    except AttributeError:\n",
    "        # aif360 inprocessing algorithm\n",
    "        y_val_pred_prob = model.predict(dataset).scores\n",
    "        pos_ind = 0\n",
    "\n",
    "    metric_arrs = defaultdict(list)\n",
    "    for thresh in thresh_arr:\n",
    "        y_val_pred = (y_val_pred_prob[:, pos_ind] > thresh).astype(np.float64)\n",
    "\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = y_val_pred\n",
    "        metric = ClassificationMetric(\n",
    "            dataset, dataset_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups\n",
    "        )\n",
    "\n",
    "        metric_arrs[\"bal_acc\"].append((metric.true_positive_rate() + metric.true_negative_rate()) / 2)\n",
    "        metric_arrs[\"avg_odds_diff\"].append(metric.average_odds_difference())\n",
    "        metric_arrs[\"disp_imp\"].append(metric.disparate_impact())\n",
    "        metric_arrs[\"stat_par_diff\"].append(metric.statistical_parity_difference())\n",
    "        metric_arrs[\"eq_opp_diff\"].append(metric.equal_opportunity_difference())\n",
    "        metric_arrs[\"theil_ind\"].append(metric.theil_index())\n",
    "\n",
    "    return metric_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_arr = np.linspace(0.01, 0.5, 50)\n",
    "val_metrics = test(dataset=dataset_orig_panel19_val, model=lr_orig_panel19, thresh_arr=thresh_arr)\n",
    "lr_orig_best_ind = np.argmax(val_metrics[\"bal_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_metrics(metrics, thresh_arr):\n",
    "    best_ind = np.argmax(metrics[\"bal_acc\"])\n",
    "    print(\"Threshold corresponding to Best balanced accuracy: {:6.4f}\".format(thresh_arr[best_ind]))\n",
    "    print(\"Best balanced accuracy: {:6.4f}\".format(metrics[\"bal_acc\"][best_ind]))\n",
    "    disp_imp_at_best_ind = 1 - min(metrics[\"disp_imp\"][best_ind], 1 / metrics[\"disp_imp\"][best_ind])\n",
    "    print(\"Corresponding 1-min(DI, 1/DI) value: {:6.4f}\".format(disp_imp_at_best_ind))\n",
    "    print(\"Corresponding average odds difference value: {:6.4f}\".format(metrics[\"avg_odds_diff\"][best_ind]))\n",
    "    print(\"Corresponding statistical parity difference value: {:6.4f}\".format(metrics[\"stat_par_diff\"][best_ind]))\n",
    "    print(\"Corresponding equal opportunity difference value: {:6.4f}\".format(metrics[\"eq_opp_diff\"][best_ind]))\n",
    "    print(\"Corresponding Theil index value: {:6.4f}\".format(metrics[\"theil_ind\"][best_ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_metrics(val_metrics, thresh_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_orig_metrics = test(\n",
    "    dataset=dataset_orig_panel19_test, model=lr_orig_panel19, thresh_arr=[thresh_arr[lr_orig_best_ind]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_metrics(lr_orig_metrics, [thresh_arr[lr_orig_best_ind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MULTIMORBIDITY\"].hist()\n",
    "df_add = df.copy()\n",
    "df_add[\"RTHLTH\"] = df_add.filter(regex=\"RTHLTH\").idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add.boxplot(column=\"MULTIMORBIDITY\", by=\"RTHLTH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = dataset.feature_names\n",
    "target = dataset.label_names[0]\n",
    "det_feature = \"MULTIMORBIDITY\"\n",
    "reverse = False\n",
    "\n",
    "df_features = df[feature_list]\n",
    "df_white, df_non_white = df_features[df_features[\"RACE\"] == 1], df_features[df_features[\"RACE\"] == 0]\n",
    "\n",
    "steps = 50\n",
    "\n",
    "is_discrete = True\n",
    "min_v = min(np.min(df_white[det_feature]), np.min(df_non_white[det_feature]))\n",
    "max_v = max(np.max(df_white[det_feature]), np.max(df_non_white[det_feature]))\n",
    "print(min_v, max_v)\n",
    "det_threshold = 1  # .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daindex.core import deterioration_index\n",
    "\n",
    "\n",
    "def get_scores(models, df, target):\n",
    "    if not isinstance(models, list):\n",
    "        models = [models]\n",
    "    predicted_probs = np.array([m.predict_proba(df.to_numpy()) for m in models])\n",
    "    return predicted_probs[:, :, 1].mean(axis=0)\n",
    "\n",
    "\n",
    "def obtain_det_alo_index(\n",
    "    df,\n",
    "    scores,\n",
    "    det_feature,\n",
    "    score_threshold,\n",
    "    cohort_name,\n",
    "    det_label=det_feature,\n",
    "    score_margin=0.05,\n",
    "    det_threshold=2,\n",
    "    min_v=-5,\n",
    "    max_v=15,\n",
    "    reverse=False,\n",
    "    is_discrete=True,\n",
    "    optimise_bandwidth=True,\n",
    "    det_feature_func=None,\n",
    "):\n",
    "    lb = score_threshold - score_margin\n",
    "    up = score_threshold + score_margin\n",
    "    det_list = []\n",
    "    i = 0\n",
    "    for _, r in df.iterrows():\n",
    "        p = scores[i]\n",
    "        if lb <= p <= up:\n",
    "            if det_feature_func is not None:\n",
    "                det_list.append(det_feature_func(r))\n",
    "            else:\n",
    "                det_list.append(r[det_feature])\n",
    "        i += 1\n",
    "    if len(det_list) > 20:\n",
    "        X = np.array(det_list)\n",
    "        di_ret = deterioration_index(\n",
    "            X[~np.isnan(X)].reshape(-1, 1),\n",
    "            min_v,\n",
    "            max_v,\n",
    "            threshold=det_threshold,\n",
    "            plot_title=f\"{cohort_name} | {det_label}\",\n",
    "            reverse=reverse,\n",
    "            is_discrete=is_discrete,\n",
    "            optimise_bandwidth=optimise_bandwidth,\n",
    "            do_plot=False,\n",
    "        )\n",
    "        return score_threshold, len(det_list), di_ret[\"k-step\"]\n",
    "    else:\n",
    "        return score_threshold, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_deterioration_index(clf):\n",
    "    white_ret = []\n",
    "    non_white_ret = []\n",
    "\n",
    "    scores1 = get_scores(clf, df_white, feature_list)\n",
    "    scores2 = get_scores(clf, df_non_white, feature_list)\n",
    "\n",
    "    # Calculate DA AUC for this fold and accumulate the values\n",
    "    for s in range(1, steps + 1):\n",
    "        white_ret.append(\n",
    "            obtain_det_alo_index(\n",
    "                df_white,\n",
    "                scores1,\n",
    "                det_feature,\n",
    "                s / steps,\n",
    "                cohort_name=\"White cohort\",\n",
    "                det_threshold=det_threshold,\n",
    "                min_v=min_v,\n",
    "                max_v=max_v,\n",
    "                is_discrete=is_discrete,\n",
    "                reverse=reverse,\n",
    "            )\n",
    "        )\n",
    "        non_white_ret.append(\n",
    "            obtain_det_alo_index(\n",
    "                df_non_white,\n",
    "                scores2,\n",
    "                det_feature,\n",
    "                s / steps,\n",
    "                cohort_name=\"Non-White cohort\",\n",
    "                det_threshold=det_threshold,\n",
    "                min_v=min_v,\n",
    "                max_v=max_v,\n",
    "                is_discrete=is_discrete,\n",
    "                reverse=reverse,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return white_ret, non_white_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_ret, non_white_ret = compute_deterioration_index(lr_orig_panel19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daindex.util import viz\n",
    "\n",
    "# Visualize White vs Non-White average DA AUC\n",
    "auc_dict = viz(\n",
    "    np.array(white_ret),\n",
    "    np.array(non_white_ret),\n",
    "    \"White\",\n",
    "    \"Non-White\",\n",
    "    f\"{det_feature}{'>='}{det_threshold}\",\n",
    "    \"Logistic Regression\",\n",
    "    config={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
